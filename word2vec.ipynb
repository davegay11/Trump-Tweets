{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# In this file we make a bag-of-words representation of the clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/clean_data/@HillaryClinton.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set nationally thrilled new york getting done ...\n",
       "1       tune hear hrc join governor cuomo la guardia c...\n",
       "2       looking forward joining governor cuomo morning...\n",
       "3       let celebrate new york state getting something...\n",
       "4       houston speak crowd committed activists @annie...\n",
       "5       rt @nickmerrill tune watch @hillaryclinton cha...\n",
       "6       check @leaninorg celebrate equalpayday percent...\n",
       "7       statistics american lives risk administration ...\n",
       "8       rt @aprildryan preach @hillaryclinton @missbea...\n",
       "9       rt @minassianmedia attention recycled false cl...\n",
       "10      let distracted let continue stand organize res...\n",
       "11      ryan born disability support family world clas...\n",
       "12      pam raising grandson parents struggling opioid...\n",
       "13      angelina young woman autism already worrying t...\n",
       "14      keith brings mother alzheimer work afford care...\n",
       "15      luisa suffered bone cancer needed care asap ho...\n",
       "16      natarsha whose breast cancer caught early scre...\n",
       "17                               fight yet forget stories\n",
       "18                                today victory americans\n",
       "19      bill speech brought tears eyes wanted share wa...\n",
       "20      rt @adamparkhomenko video son sang sent hillar...\n",
       "21      rt @repadamschiff intelligence community concl...\n",
       "22      rt @vitalvoices throwback gla w honorable @hil...\n",
       "23                                   things learned today\n",
       "24      internationalwomensday thinking young girl oth...\n",
       "25        good message anytime especially embraceambition\n",
       "26            rt @nickmerrill warm welcome boston morning\n",
       "27      thanks pres johnson entire wellesley community...\n",
       "28      trump @dhsgov confirmed weekend ban enhance se...\n",
       "29      threats hate crimes rise tell @potus part must...\n",
       "                              ...                        \n",
       "3202    introducing hillary en espa ol new account bri...\n",
       "3203    pretty obvious know lot issues @senatemajldr t...\n",
       "3204                                     much party unity\n",
       "3205    rt @johnkasich one benefit casting commitment ...\n",
       "3206    dummy slob animal @realdonaldtrump said trumpy...\n",
       "3207    mike pence introduced america last night learn...\n",
       "3208    rt @mikereedschmidt happy anniversary dodd fra...\n",
       "3209    hard keep track ignorant divisive things trump...\n",
       "3210                   might good time follow us snapchat\n",
       "3211    sniveling coward carnival barker things republ...\n",
       "3212    hillary spent career helping others @realdonal...\n",
       "3213        know trump really thinks us sad trumpyourself\n",
       "3214    rt @ryanegraney best thing ever donald trump s...\n",
       "3215    charge would know waterboarding baptize terror...\n",
       "3216    introducing trumpyourself discover @realdonald...\n",
       "3217    represent us ideas represent us values represe...\n",
       "3218             donald trump occasionally right rncincle\n",
       "3219                                      vote conscience\n",
       "3220                              boo buck trump rncincle\n",
       "3221    rt @thebriefing @mike pence speaking abandonin...\n",
       "3222    mike pence tried legalize lgbt discrimination ...\n",
       "3223                                    say mike rncincle\n",
       "3224    rt @mikereedschmidt pence touting indiana econ...\n",
       "3225    thought donald trump going pick running mate w...\n",
       "3226    rt @thebriefing mike pence bigotry heaping sid...\n",
       "3227    donald trump chose one anti lgbt politicians c...\n",
       "3228    things know trump v p p c k convention speaker...\n",
       "3229    rt @thebriefing newt compared planned parentho...\n",
       "3230    rt @hillary esp ahora le toca el turno en la c...\n",
       "3231    made thought newt might trump vp pick go anywa...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-22 13:06:10,386 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2017-04-22 13:06:10,396 : INFO : collecting all words and their counts\n",
      "2017-04-22 13:06:10,397 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-22 13:06:10,412 : INFO : collected 5447 word types from a corpus of 31549 raw words and 3232 sentences\n",
      "2017-04-22 13:06:10,413 : INFO : Loading a fresh vocabulary\n",
      "2017-04-22 13:06:10,465 : INFO : min_count=1 retains 5447 unique words (100% of original 5447, drops 0)\n",
      "2017-04-22 13:06:10,466 : INFO : min_count=1 leaves 31549 word corpus (100% of original 31549, drops 0)\n",
      "2017-04-22 13:06:10,493 : INFO : deleting the raw counts dictionary of 5447 items\n",
      "2017-04-22 13:06:10,495 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2017-04-22 13:06:10,496 : INFO : downsampling leaves estimated 28079 word corpus (89.0% of prior 31549)\n",
      "2017-04-22 13:06:10,497 : INFO : estimated required memory for 5447 words and 300 dimensions: 15796300 bytes\n",
      "2017-04-22 13:06:10,517 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-22 13:06:10,650 : INFO : training model with 4 workers on 5447 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2017-04-22 13:06:10,804 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-22 13:06:10,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-22 13:06:10,824 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-22 13:06:10,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-22 13:06:10,826 : INFO : training on 157745 raw words (140342 effective words) took 0.2s, 820445 effective words/s\n",
      "2017-04-22 13:06:10,827 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-04-22 13:06:10,829 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-22 13:06:10,893 : INFO : saving Word2Vec object under trump2vec.bin, separately None\n",
      "2017-04-22 13:06:10,894 : INFO : not storing attribute syn0norm\n",
      "2017-04-22 13:06:10,895 : INFO : not storing attribute cum_table\n",
      "2017-04-22 13:06:11,085 : INFO : saved trump2vec.bin\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(\n",
    "            [s.split() for s in list(df['clean_text'])], \n",
    "            workers=num_workers, size=num_features, \\\n",
    "            min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# calling init_sims make the training more efficient if we don't plan on\n",
    "# training the model any further\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"trump2vec.bin\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 0.9999815821647644),\n",
       " ('@hillaryclinton', 0.9999810457229614),\n",
       " ('rt', 0.9999803900718689),\n",
       " ('people', 0.9999784231185913),\n",
       " ('country', 0.9999778270721436),\n",
       " ('one', 0.9999773502349854),\n",
       " ('president', 0.9999765753746033),\n",
       " ('let', 0.9999746084213257),\n",
       " ('us', 0.9999741911888123),\n",
       " ('every', 0.9999741911888123)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cool! Now the model is trained...let's have some fun\n",
    "model.most_similar(\"hillary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earned', 0.9616687893867493),\n",
       " ('strongertogether', 0.9616281986236572),\n",
       " ('klan', 0.9612427949905396),\n",
       " ('loved', 0.9610686898231506),\n",
       " ('khan', 0.9610077142715454),\n",
       " ('read', 0.9609919786453247),\n",
       " ('owner', 0.9609329104423523),\n",
       " ('ago', 0.9608713984489441),\n",
       " ('looks', 0.9608465433120728),\n",
       " ('workers', 0.960839033126831)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 0.9998796582221985),\n",
       " ('hillary', 0.9998775720596313),\n",
       " ('rt', 0.9998752474784851),\n",
       " ('@hillaryclinton', 0.999874472618103),\n",
       " ('america', 0.9998737573623657),\n",
       " ('campaign', 0.9998724460601807),\n",
       " ('american', 0.9998717308044434),\n",
       " ('every', 0.9998700618743896),\n",
       " ('donald', 0.9998698830604553),\n",
       " ('work', 0.9998685121536255)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"jobs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
