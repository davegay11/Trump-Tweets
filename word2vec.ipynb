{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# In this file we make a bag-of-words representation of the clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./clean_data/clean_tweets.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        trump international tower chicago ranked th ta...\n",
       "1                     wishing happy bountiful thanksgiving\n",
       "2        donald trump partners tv new reality series en...\n",
       "3        hear donald trump discuss big gov spending ban...\n",
       "4        watch video ivanka trump sharing business advi...\n",
       "5        read donald trump say daughter ivanka upcoming...\n",
       "6        lot people imagination execute execute imagina...\n",
       "7                   read donald trump top ten tips success\n",
       "8        hysterical dsrl videos featuring donald trump ...\n",
       "9        donald trump bids buy oreo double stuf racing ...\n",
       "10       reminder miss universe competition live bahama...\n",
       "11       watch miss universe competition live bahamas s...\n",
       "12       watch donald trump recent appearance late show...\n",
       "13       ivanka twitter follow @ivankatrump terrific we...\n",
       "14       browse donald trump summer reading list busine...\n",
       "15       check list donald trump books summer reading t...\n",
       "16       congrats winners around world entered think li...\n",
       "17       donald trump backs apprentice randal pinkett n...\n",
       "18       aware things seem inexplicable big step toward...\n",
       "19       safe happy independence day one enjoy donald j...\n",
       "20       watch powerful frank interview donald trump ec...\n",
       "21       wishing happy father day dad champion today ev...\n",
       "22       fb vanity urls sf chronicle david beckham one ...\n",
       "23           today donald trump birthday send b day wishes\n",
       "24       last week enter think like champion signed boo...\n",
       "25            check donald trump new igoogle showcase page\n",
       "26       know call quits keep moving forward donald j t...\n",
       "27         read excerpt think like champion donald j trump\n",
       "28       higher self direct opposition comfort zone don...\n",
       "29             know donald trump facebook become fan today\n",
       "                               ...                        \n",
       "26715    time republicans democrats get together come h...\n",
       "26716    typical political thing blame fact obamacare l...\n",
       "26717    democrats lead head clown chuck schumer know b...\n",
       "26718    jackie evancho album sales skyrocketed announc...\n",
       "26719    massive increases obamacare take place year de...\n",
       "26720    like hike arizona also deductibles high practi...\n",
       "26721    republicans must careful dems failed obamacare...\n",
       "26722    things said like giving questions debate h tot...\n",
       "26723    somebody hacked dnc hacking defense like rnc r...\n",
       "26724    thank ford scrapping new plant mexico creating...\n",
       "26725    julian assange said year old could hacked pode...\n",
       "26726    intelligence briefing called russian hacking d...\n",
       "26727    general news conference january eleventh n c t...\n",
       "26728       trump already delivering jobs promised america\n",
       "26729    releases gitmo extremely dangerous people allo...\n",
       "26730    instead driving jobs wealth away america becom...\n",
       "26731    @danscavino ford scrap mexico plant invest mic...\n",
       "26732    may number one act priority focus tax reform h...\n",
       "26733    congress work really make weakening independen...\n",
       "26734    democrat governor minnesota said affordable ca...\n",
       "26735    people must remember obamacare work affordable...\n",
       "26736    general motors sending mexican made model chev...\n",
       "26737    china taking massive amounts money wealth u to...\n",
       "26738    north korea stated final stages developing nuc...\n",
       "26739    thought felt would win big easily fabled cance...\n",
       "26740    various media outlets pundits say thought goin...\n",
       "26741    @cnn released book called unprecedented explor...\n",
       "26742    chicago murder rate record setting shooting vi...\n",
       "26743     well new year begins together make america great\n",
       "26744    rt @donaldjtrumpjr happy new year everyone new...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-21 06:32:40,075 : INFO : collecting all words and their counts\n",
      "2017-03-21 06:32:40,088 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-03-21 06:32:40,114 : INFO : PROGRESS: at sentence #10000, processed 91795 words, keeping 14197 word types\n",
      "2017-03-21 06:32:40,144 : INFO : PROGRESS: at sentence #20000, processed 188646 words, keeping 23890 word types\n",
      "2017-03-21 06:32:40,165 : INFO : collected 28314 word types from a corpus of 254373 raw words and 26745 sentences\n",
      "2017-03-21 06:32:40,167 : INFO : Loading a fresh vocabulary\n",
      "2017-03-21 06:32:40,198 : INFO : min_count=10 retains 3220 unique words (11% of original 28314, drops 25094)\n",
      "2017-03-21 06:32:40,200 : INFO : min_count=10 leaves 207305 word corpus (81% of original 254373, drops 47068)\n",
      "2017-03-21 06:32:40,258 : INFO : deleting the raw counts dictionary of 28314 items\n",
      "2017-03-21 06:32:40,260 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2017-03-21 06:32:40,262 : INFO : downsampling leaves estimated 184185 word corpus (88.8% of prior 207305)\n",
      "2017-03-21 06:32:40,263 : INFO : estimated required memory for 3220 words and 300 dimensions: 9338000 bytes\n",
      "2017-03-21 06:32:40,310 : INFO : resetting layer weights\n",
      "2017-03-21 06:32:40,402 : INFO : training model with 4 workers on 3220 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2017-03-21 06:32:40,404 : INFO : expecting 26745 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-03-21 06:32:41,452 : INFO : PROGRESS: at 49.26% examples, 443122 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-21 06:32:42,284 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-03-21 06:32:42,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-03-21 06:32:42,304 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-03-21 06:32:42,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-03-21 06:32:42,308 : INFO : training on 1271865 raw words (921223 effective words) took 1.9s, 492857 effective words/s\n",
      "2017-03-21 06:32:42,792 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-03-21 06:32:42,895 : INFO : saving Word2Vec object under trump2vec.bin, separately None\n",
      "2017-03-21 06:32:42,897 : INFO : not storing attribute syn0norm\n",
      "2017-03-21 06:32:42,899 : INFO : not storing attribute cum_table\n",
      "2017-03-21 06:32:43,271 : INFO : saved trump2vec.bin\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(\n",
    "            [s.split() for s in list(df['clean_text'])], \n",
    "            workers=num_workers, size=num_features, \\\n",
    "            min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# calling init_sims make the training more efficient if we don't plan on\n",
    "# training the model any further\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"trump2vec.bin\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clinton', 0.9656050801277161),\n",
       " ('obama', 0.9429252743721008),\n",
       " ('china', 0.938691258430481),\n",
       " ('bad', 0.9173334836959839),\n",
       " ('@barackobama', 0.9101584553718567),\n",
       " ('money', 0.886329174041748),\n",
       " ('obamacare', 0.8773565888404846),\n",
       " ('must', 0.872538685798645),\n",
       " ('said', 0.8722615838050842),\n",
       " ('crooked', 0.8615908622741699)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cool! Now the model is trained...let's have some fun\n",
    "model.most_similar(\"hillary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('replace', 0.9992004036903381),\n",
       " ('gave', 0.9988620281219482),\n",
       " ('lost', 0.998856246471405),\n",
       " ('ago', 0.9988492727279663),\n",
       " ('high', 0.9983710050582886),\n",
       " ('dumb', 0.9980428218841553),\n",
       " ('delay', 0.997380256652832),\n",
       " ('@nytimes', 0.9966719150543213),\n",
       " ('taken', 0.9966075420379639),\n",
       " ('dishonest', 0.9964410066604614)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('must', 0.986316978931427),\n",
       " ('us', 0.9856156706809998),\n",
       " ('stop', 0.981418251991272),\n",
       " ('never', 0.9735686779022217),\n",
       " ('wants', 0.9718760848045349),\n",
       " ('deal', 0.9709449410438538),\n",
       " ('china', 0.9703025221824646),\n",
       " ('u', 0.9645163416862488),\n",
       " ('obama', 0.962763786315918),\n",
       " ('take', 0.9567989706993103)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truncated</th>\n",
       "      <th>text</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [truncated, text, is_quote_status, id, favorite_count, source, retweeted, retweet_count, favorited, lang, created_at, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
